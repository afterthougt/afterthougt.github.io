---
layout: post
title: 딥러닝 기본
category: cs
tags: ai

---

# 딥러닝 기본

<aside>
💡 딥 러닝 실무가가 갖추어야 할 요소?

</aside>

- 구현 스킬
- 수학 능력 - 선형대수학, 확률 등
- 많은 최신 논문을 파악하고 있는 것

## 개요

- AI? — 사람의 지능 모방하는 것(Mimic human intelligence)
- ML? — 데이터 접근 방식(Data-driven approach)
- DL? — 신경망(Neural networks)

### 딥 러닝의 주요 구성 요소

- 모델이 학습 가능한 **데이터**<sub>The **data** that the model can learn from</sub>
- 데이터 변환 방법이 담긴 **모델**<sub>The **model** on how to transform the data</sub>
- 모델 성능을 정량화할 **손실 함수**<sub>The **loss function** that quantifies the badness of the model</sub>
- 손실 함수 최소화를 위해 파라미터를 조정하기 위한 **알고리즘**<sub>The **algorithm** to adjust the parameters to minimize the loss</sub>

### 데이터

- 데이터는 풀고자 하는 문제 종류에 따라 다르다.
    - 분류<sub>Classification</sub>
    - 의미적 분할<sub>Semantic segmentation</sub>
    - 탐지<sub>Detection</sub>
    - 포즈 추정<sub>Pose estimation</sub>
    - 시각 정보 기반 질의응답<sub>Visual Q&A</sub>

### 모델

(예) AlexNet, GoogLeNet, ResNet, DenseNet, LSTM, Deep AutoEncoders, GAN, …

### 손실 함수

- 이루고자 하는 것의 근사치(proxy)에 불과. loss가 줄어드는 것이 꼭 원하는 목적을 달성하는 것을 의미하는 것은 아님. 관계를 이해하는 것이 새로운 연구를 하는 데 도움이 됨.
    
    - 회귀<sub>Regression</sub>
        
        $$
        \text{MSE}=\frac{1}{N}\sum_{i=1}^N\sum_{d=1}^D\left(y_i^{(d)}-\hat y_i^{(d)}\right)^2
        $$
        
    - 분류<sub>Classification</sub>
        
        $$
        \text{CE}=-\frac{1}{N}\sum_{i=1}^N\sum_{d=1}^Dy_i^{(d)}\log\hat y_i^{(d)}
        $$
        
    - 확률 기반
        
        $$
        \text{MLE}=\frac{1}{N}\sum_{i=1}^N\sum_{d=1}^D\log \mathcal N\left(y_i^{(d)};\hat y_i^{(d)},1\right)
        $$
        

### 최적화 알고리즘

(예) SGD, Momentum, NAG, Adagrad, Adadelta, Rmsprop

그밖의 테크닉: dropout, early stopping, k-fold validation, weight decay, batch normalization, mixup, ensemble, bayesian optimization, …

## 딥 러닝의 역사

<aside>
💡 논문: Denny Britz, Deep Learning’s Most Important Ideas — A Brief Historical Review (2020-07-29)

</aside>

### 2012 — AlexNet

- CNN
- 224 x 224 이미지 분류
- ImageNet 대회 1등
- 딥 러닝 방법으로 처음 1등, 그 이후 대회에는 딥 러닝 아닌 방법이 한 번도 1등을 한 적이 없음 → 패러다임 변화

### 2013 — DQN

- Google Deepmind가 Atari 게임을 풀기 위해 강화학습으로 사용한 방법

### 2014 — Encoder/Decoder, Adam

- NMT를 풀기 위해 나온 방법론
- 단어의 연속이 주어졌을 때, 다른 언어의 단어의 연속으로 어떻게 바꿀지?
- 기계어 번역의 트렌드가 바뀜
- 왜 Adam을 사용하는가?
    
    → Adam이 결과가 잘 나와서
    
- cifar-10 데이터셋 학습 시킨 네트워크가 처음 나왔을 때 어떻게 학습시켰는지를 살펴보면, ResNet같은 아키텍처를 기본적으로 사용하고 학습이 절반 정도 진행(전체 epochs의 절반)되었을 때 learning rate을 10% 수준으로 낮춤. (이때 SGD 쓰긴 했음.) 학습이 75% 정도 진행했을 때 다시 learning rate 10% 정도 줄임
- 왜 이렇게 하는지에 대한 이야기는 없는데, 이런 식으로 세팅을 하지 않으면 같은 결과가 복원이 안 된다고 함 → 더 안 좋은 성능
- 결과 재현에 있어서 Adam 방법론은 ‘웬만하면 잘 된다’는 의미가 있음

### 2015 — GAN, ResNet

- GAN: Generative Adversarial Network
- 생성 모델 — 중요하고 강조하는 토픽
- 감사의 인사: “Finally, we would like to thank Les Trois Brasseurs for stimulating our creativity.” 술집의 술이 맛이 없어서 연구를 생각하다가 떠오른 아이디어가 GAN
- Residual Networks의 의의?
    - 이 연구 덕분에 딥 러닝이 딥 러닝이 가능해졌다(?) → 네트워크를 깊게 쌓기 때문에 딥 러닝이라는 설명이 있음
    - 한편 신경망을 깊게 쌓으면 트레이닝 에러는 더 작아지더라도 테스트 에러가 오히려 커지는 과적합<sub>overfitting</sub> 현상이 알려져 있었는데, 이 문제를 해결

### 2017 — Transformer

- 논문 제목: Attention Is All You Need
- 도발적이고 도전적인 제목: 일반적인 논문 제목은 풀고자 하는 문제와 어떻게 풀었는지를 설명한다든지 만들고자하는 네트워크의 성질을 잘 표현하게끔 네이밍을 함!
- 트랜스포머<sub>Transformer</sub> 구조는 웬만한 RNN 구조를 대체했고, 컴퓨터 비전 분야까지도 섭렵
- Multihead attention 구조를 이해하는 것은 매우 중요

### 2018 — BERT

- 웹에 산재해있는 말뭉치(위키피디아 등)를 이용해 사전학습<sub>pre-training</sub> 학습
- 그 후 정말 풀고자하는 문제의 소드 데이터에 파인튜닝<sub>fine-tuning</sub>
- Fine-tuned NLP models 발전하기 시작

### 2019 — Big Language Models (GPT-X)

- Fine-tuned NLP model의 끝판왕 느낌으로도 볼 수 있음
- GPT-3 특징: BERT와 다르게 굉장히 많은 수의 파라미터 수. 175B params.

### 2020 — Self-Supervised Learning

- SimCLR: a simple framework for contrastive learning of visual representations
- 해결하고자 하는 문제 수준 대비 데이터가 적을 때, 모델 혹은 loss 함수 등을 바꿔가며 여러가지 다른 변경사항을 주는 것이 일반적인 방법이었다면
- Self-supervised learning의 경우, 주어진 데이터 외에 정답 레이블을 모르는 unsupervised data를 이용하겠다는 아이디어
- 어떻게 하면 이미지를 컴퓨터가 잘 이해할 수 있는 벡터로 바꿀 수 있을 것인가?
- 학습 데이터 뿐만 아니라 unsupervised data까지 동원하여 문제를 풀고자 함

# 신경망 & 다층 퍼셉트론(Neural Networks & Multi-Layer Perceptron)

- 딥 러닝/뉴럴 네트워크가 무엇인지
- 딥 러닝의 가장 간단한 구조(MLP)가 어떤 것인지
- 딥 러닝을 ‘학습’한다는 것의 의미

## 신경망

<aside>
💡 “Neural networks are computing systems vaguely inspired by the biological neural networks that constitute animal brains.” (Wikipedia)

</aside>

- 사람의 뇌를 모방했기 때문에 → 잘 된다?
- 꼭 이렇게 설명할 필요가 없는 이유? 역전파(backpropagation)이 인간의 뇌에서 일어나는가를 살펴보면 아니라는 쪽의 대답을 하게 될 것
- 하늘을 나는 구조체의 발명의 역사에 빗대어 설명해보자면
    - Clèment Ader’s Avion III (1897)
    - Write Brothers (1903)
    - F-22 Raptor
    
    처음에는 새를 모방하려고 했을지 몰라도 새를 꼭 모방을 하지는 않아도 하늘을 날게 할 수 있음
    
- 신경망은 '아핀 변환 - 비선형 변환' 구조가 반복하여 쌓이는 함수 근사식이다(Neural networks are function approximators that stack affine transformations followed by nonlinear transformations).

## 선형 신경망

- 데이터: $$\mathcal D=\{(x_i,y_i)\}_{i=1}^N$$
- 모델: $$\hat y=wx+b$$
- 손실: $$\text{loss}=\frac{1}{n}\sum\limits_{i=1}^N(y_i-\hat y_i)^2$$

### $$w, b$$ 찾는 법?

→ 역전파<sub>Backpropagation</sub>

- 최적화 변수에 관해 편미분을 계산:
    
    $$
    \begin{aligned}
    \frac{\partial\text{loss}}{\partial w}&=\frac{\partial}{\partial w}\frac{1}{N}\sum_{i=1}^N(y_i-\hat y_i)^2\\
    &=\frac{\partial}{\partial w}\frac{1}{N}\sum_{i=1}^N(y_i-wx_i-b)^2\\
    &=-\frac{1}{N}\sum_{i=1}^N-2(y_i-wx_i-b)
    \end{aligned}
    $$
    
- 최적화 변수를 반복하여 갱신:
    
    $$
    \begin{aligned}
    w\leftarrow w-\eta\frac{\partial\text{loss}}{\partial w}\\
    b\leftarrow b-\eta\frac{\partial\text{loss}}{\partial b}
    \end{aligned}
    $$
    
    - 적당한 $$\eta$$ 값이 중요. 크면 학습이 잘 안 됨.

### 행렬곱에 대한 해석?

- 두 벡터 공간 사이의 선형 변환을 찾겠다는 것 ($$W$$)

### 비선형성 추가 이유?

- 단순한 선형 결합의 연속은 한 번의 선형 결합과 동치

### 활성화 함수(activation functions)

- ReLU, Sigmoid, tanh
- 어떤 것이 제일 좋을지는 문제마다, 상황마다 다름 → 엔지니어링 감각!?

## 선형 신경망을 넘어서?

- Kur Hornik, Multilayer Feedforward Networks are Universal Approximators
- English: “There is a single hidden layer feedforward network that approximates any measurable function to any desired degree of accuracy on some compact set K.”
- Math:
  For every function $$g$$ in $$M^r$$ there is a compact subset $$K$$ of $$R^r$$ and an $$f\in\sum^r(\Psi)$$ such that for any $$\epsilon>0$$ we have $$\mu(K)<1-\epsilon$$ and for every $$X\in K$$ we have $$|f(x)-g(x)|<\epsilon$$, regardless of $$\Psi$$, $$r$$, or $$\mu$$.
    
- 그러한 신경망의 존재성만을 보장하는 것일 뿐, 학습 시킨 신경망 구조가 최적해일 것이라는 보장 x. 어떻게 찾는지는 모른다.

## 다층 퍼셉트론(Multi-Layer Perceptron)

- 이와 같은 구조를 MLP라 부름
- 깊게 쌓을 수도 있음
- 손실 함수?
    
    cf. $$\hat y$$을 보통 logit이라고 많이 부름
    
    - 회귀<sub>Regression</sub>
        
        $$
        \text{MSE}=\frac{1}{N}\sum_{i=1}^N\sum_{d=1}^D\left(y_i^{(d)}-\hat y_i^{(d)}\right)^2
        $$
        
        - 꼭 제곱이어야 할 것인가?
        - L1-norm, L2-norm 사용할 때의 성질이 조금 달라짐. → Outlier가 있을 때, 그 데이터에 신경망이 맞추려고 하다가 신경망이 망가지곤 함. 이 경우에는 L1-norm이 L2-norm에 비해 outlier에 더 robust할 수 있음.
    - 분류<sub>Classification</sub>
        
        $$
        \text{CE}=-\frac{1}{N}\sum_{i=1}^N\sum_{d=1}^Dy_i^{(d)}\log\hat y_i^{(d)}
        $$
        
        - 과연 cross entropy loss가 분류 문제를 푸는 데 최적일까?
        - 클래스 $$y_i^{(d)}$$는 한 개만 1, 나머지는 0이어서 해당 클래스의 $$\hat y_i^{(d)}$$가 다른 것들보다 크기만 하면 됨. 즉 $\hat y_i^{(d)}$ 간의 상대적인 관계를 따지는 것.
    - 확률 기반
        
        $$
        \text{MLE}=\frac{1}{N}\sum_{i=1}^N\sum_{d=1}^D\log \mathcal N\left(y_i^{(d)};\hat y_i^{(d)},1\right)
        $$
        
        - Confidence, uncertainty 정보 등을 함께 찾고자 할 때 probabilistic loss function을 사용하게 됨.

## 참고
- [부스트코스 - 딥러닝 기초 다지기](https://www.boostcourse.org/ai111){:target="_blank"}
